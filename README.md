# SeaBook - Plataforma de Préstamos Bibliotecarios en AWS

# **1.Descripción del Proyecto**:
SeaBook es una plataforma digital peruana diseñada para gestionar el préstamo de libros en el sistema de bibliotecas universitarias de la UTP (Universidad Tecnológica del Perú). Este proyecto 
representa una transformación completa de su arquitectura monolítica original a una moderna, escalable, segura y resiliente en Amazon Web Services (AWS), siguiendo las mejores prácticas 
de Infraestructura como Código (IaC).El objetivo principal es garantizar la continuidad del servicio y una experiencia de usuario óptima para más de 150,000 alumnos en 15 campus a nivel nacional, especialmente 
durante picos de alta demanda.

# **2. La Problemática de SeaBook**:
  La situación original:
  + Arquitectura monolítica: Un único servidor de aplicación y una sola base de datos.
  + Problemas de rendimiento: Caídas frecuentes y tiempos de respuesta de más de 2 minutos durante inicios de semestre, matrículas y exámenes.
  + Falta de escalabilidad: Incapacidad para manejar miles de solicitudes concurrentes.
  + Sin tolerancia a fallos: Un punto único de fallo que afectaba la disponibilidad del servicio. 

  Nuestra solución: Una arquitectura moderna en AWS que aborda estos problemas mediante la implementación de alta disponibilidad, escalado automático, seguridad robusta y un pipeline de despliegue automatizado.

## **3. Tabla de Arquitectura - Flujo de Conexión y Servicios AWS**:

| N° | Atributo de Calidad (Ility) | Requerimientos No Funcional (RNF) | Concepto / Tecnología que lo resuelve |
|:--:|:---|:---|:---|
| **1** | **Rendimiento** | a) El tiempo de carga de la página de inicio debe ser inferior a 2 segundos bajo carga normal. b) El 95% de búsquedas debe responder en < 200 ms manejando 50 GB de catálogo (500k libros x 100 KB metadata) + 10 GB logs transacciones (1M préstamos/año) | El flujo de conexión comienza con Amazon Route 53 y AWS Global Accelerator. Cuando el alumno inicia una reserva desde cualquiera de los 15 campus, el tráfico es dirigido mediante una 'autopista privada' de AWS para evitar la congestión del internet público. La coherencia técnica de este paso se basa en la regla de enrutamiento por latencia y salud del endpoint, lo que garantiza que el estudiante siempre sea conectado al centro de datos más rápido y disponible. |
| **2-4** | **Seguridad** | c) La comunicación entre el navegador del estudiante y el servidor debe estar cifrada para proteger la información transmitida. d) Las credenciales de acceso a la base de datos no deben estar visibles ni almacenadas en texto plano dentro del código fuente. e) El sistema debe bloquear automáticamente direcciones IP que realicen más de 10 intentos fallidos de inicio de sesión por minuto, con el fin de prevenir ataques de fuerza bruta. f) El sistema debe mitigar ataques DDoS y tráfico malicioso sin caída del servicio, manteniendo la disponibilidad durante picos de solicitudes. g) Todo acceso administrativo debe requerir MFA y privilegios mínimos; los accesos a recursos deben estar segregados por ambiente (dev/test/prod). | El flujo de seguridad y acceso comienza con AWS Shield y AWS WAF, que actúan como un sistema de vigilancia de élite en la entrada principal; estos detectan "multitudes artificiales" (ataques DDoS) y bloquean comportamientos sospechosos antes de que ingresen a la red interna, aplicando una ventana rodante de 5 minutos que garantiza que el límite de tasa de peticiones no se reinicie, sino que se desplace continuamente para una protección ininterrumpida. Inmediatamente después, el tráfico pasa por Amazon API Gateway y Amazon Cognito, capa encargada de validar las credenciales digitales del alumno (login), donde si se detectan múltiples fallos, el "torniquete" de acceso se bloquea automáticamente mediante un mecanismo de Throttling con un límite estricto de 10 intentos de validación por minuto, mitigando eficazmente cualquier ataque de fuerza bruta. Finalmente, todo el proceso de reserva se resguarda dentro de una VPC con subredes privadas, asegurando que la lógica operativa ocurra en un área restringida e invisible desde el internet público, utilizando un NAT Gateway para permitir salidas seguras a la red sin exponer jamás la dirección IP privada de los servidores al exterior. |
| **5** | **Resiliencia** | h) 99.99% disponibilidad si falla AZ (Lima, Trujillo, Arequipa); fallback <10s a AZ saludable. Soporta 15 sedes simultáneas con 10k usuarios/sedes. | Posteriormente, el tráfico es gestionado por el Application Load Balancer (ALB), que actúa como un jefe de pasillo encargado de inspeccionar cada 5 segundos que los bibliotecarios (servidores) estén sanos antes de asignarles alumnos; esto se logra mediante una configuración estricta de Health Checks, la cual garantiza que, si un servidor deja de responder, el tráfico se desvíe automáticamente en menos de 5 segundos hacia un nodo operativo, asegurando la continuidad del servicio. |
| **6** | **Escalabilidad** | i) El sistema debe ser capaz de procesar todos los picos de alta concurrencia generados durante las semanas de clases y exámenes sin que los usuarios perciban lentitud o bloqueos. j) La base de datos debe ser capaz de procesar 1,000 transacciones de lectura por segundo con una latencia menor a 50 ms. | Posteriormente, la potencia de cómputo es provista por las instancias Amazon EC2 (Worker Nodes), que funcionan como los servidores físicos que sostienen las ventanillas de atención al cliente; estas operan bajo la lógica de Auto Scaling Groups, una regla técnica que permite que las máquinas se creen o destruyan automáticamente en función del uso de CPU, garantizando que el sistema siempre cuente con los recursos necesarios para atender la demanda. |
| **7** | **Disponibilidad** | k) El sistema debe garantizar la continuidad operativa y el acceso ininterrumpido a los servicios bibliotecarios durante todo el horario de atención académica (lunes a domingo) y periodos de evaluación. l) Si el servidor principal falla, el tráfico debe redirigir automáticamente a una instancia sana en menos de 5 segundos. m) No debe existir un punto único de fallo (Single Point of Failure) en la capa de aplicación. | Sobre esta base, Amazon EKS (Kubernetes) actúa como el administrador principal que orquesta la apertura de más ventanillas de atención (Pods) cuando se detecta una alta afluencia de alumnos por exámenes; este proceso se rige por la regla técnica de HPA/VPA al 80%, la cual permite que el sistema escale automáticamente al alcanzar dicho umbral de carga, garantizando la estabilidad operativa del microservicio de reservas. |
| **8** | **Mantenibilidad** | n) Los cambios en la configuración de la infraestructura deben ser versionables y auditables, permitiendo un control adecuado de las modificaciones realizadas. o) El sistema debe estar desacoplado, de modo que los cambios en el Frontend no requieran reiniciar ni afectar la Base de Datos. | Para asegurar la comunicación interna, Amazon App Mesh permite que el microservicio de "Reservas" interactúe con el de "Usuarios" de forma fluida y segura; esto se logra mediante la regla técnica de descubrimiento automático de servicios, la cual garantiza que los componentes se reconozcan y conecten entre sí de manera dinámica, incluso si cambian de ubicación dentro del cluster o se despliegan en nuevos nodos. |
| **9** | **Rendimiento** | ñ) Procesar 500 préstamos concurrentes (<2s 95%) almacenando 2TB total (catálogo + transacciones + analytics). | Complementando esta fluidez, Amazon ElastiCache (Redis) y OpenSearch funcionan como aceleradores de datos, manteniendo los libros más pedidos en una "mesa de consulta rápida" para su acceso inmediato; esto se potencia mediante el uso de índices GIN, una regla técnica que permite realizar búsquedas de texto completo en milisegundos sobre un catálogo de más de 500,000 libros, optimizando drásticamente la experiencia del usuario. |
| **10** | **Fiabilidad** | p) 1M transacciones/mes (año 1) escalando a 2M/mes (año 2) con 100% ACID sin pérdida de datos. q) 0% corrupción ante caídas, escalando datos de 2TB → 100 TB en 3 años. | Para garantizar la persistencia de la información, Amazon Aurora Serverless v2 actúa como el almacén central de datos que escala su capacidad automáticamente para procesar hasta 1,000 transacciones por segundo; este componente se rige bajo la regla técnica de Multi-AZ, la cual mantiene réplicas en distintas sedes físicas para asegurar la integridad de los datos (ACID) y evitar cualquier pérdida de registros ante fallos en un centro de datos. |
| **11** | **Resiliencia** | r) El sistema deberá gestionar la concurrencia de solicitudes mediante una cola FIFO que garantice la integridad transaccional (cero pérdidas/duplicados) y soporte picos de carga de hasta 3,000 TPS (transacciones por segundo) sin degradación del servicio. | Para asegurar un flujo de trabajo ordenado, las solicitudes de reserva se gestionan a través de Amazon SQS (FIFO), una cola de mensajería que garantiza que ninguna petición se pierda ni se duplique al procesarse en la secuencia exacta en que fue recibida; este componente opera bajo la regla técnica de un límite de 3,000 mensajes por segundo, lo que proporciona la capacidad máxima necesaria para procesar ráfagas masivas de reservas sin degradar el servicio. |
| **12** | **Recuperabilidad** | s) El Tiempo Objetivo de Recuperación (RTO) debe ser menor a 15 minutos ante desastre en AZ principal (Lima); promover AZ secundaria (Trujillo) para todas las 15 sedes en el Perú. t) El Punto Objetivo de Recuperación (RPO) del sistema debe ser de máximo 5 minutos, garantizando una pérdida mínima de datos ante incidentes que afecten la continuidad del servicio. | Como mecanismo de protección, si una reserva no puede procesarse tras varios intentos, el mensaje se redirige y guarda en una SQS Dead Letter Queue (DLQ), que funciona como un "buzón de incidencias" para evitar la pérdida de cualquier pedido; este componente se rige por la regla técnica de aislamiento de seguridad, la cual garantiza que las políticas de acceso de la cola principal no comprometan la integridad de la DLQ, permitiendo un análisis de errores independiente sin afectar el flujo operativo general. |
| **11** (sic) | **Rendimiento** | u) El sistema deberá realizar las tareas de procesamiento intensivo (generación de documentos y notificaciones) de manera asíncrona y desacoplada, asegurando que el tiempo de respuesta de la interfaz de usuario no exceda los 500 milisegundos y evitando el consumo de CPU en el servidor transaccional principal. | Para la fase de finalización, se implementa una arquitectura Serverless utilizando AWS Lambda y Amazon SNS. Este módulo se encarga de la generación del comprobante en PDF y la notificación inmediata al usuario mediante un patrón de ejecución asíncrona basada en eventos. Este diseño permite desacoplar las tareas de alto consumo de cómputo, evitando la saturación de las instancias EC2 y garantizando la baja latencia en el hilo principal de la aplicación. |
| **12** | **Auditabilidad** | v) El sistema debe registrar acciones de administración y cambios de configuración, con retención mínima de 365 días y capacidad de trazabilidad por incidente. | Para asegurar la transparencia y el cumplimiento normativo, AWS CloudTrail y Amazon S3 Object Lock actúan como una cámara de vigilancia que graba cada acción realizada en el sistema, generando un registro inmutable bajo el modelo WORM (escritura única, lectura múltiple); esta configuración garantiza que nadie pueda borrar la evidencia de las operaciones, cumpliendo con la regla técnica de retención de 365 días para satisfacer los estándares más estrictos de control y auditoría institucional. |
| **13** | **Observabilidad** | w) El sistema debe generar alertas automáticas cuando el uso del CPU sea en promedio de ≥ 80% durante 5 minutos consecutivos, y debe notificar en 60 segundos o menos desde que se cumple la condición, enviando la alerta y proceder con la auto-remediación controlada, sólo cuando la alerta sea severidad critical y el error se repita 2 veces en 10 minutos. x) El sistema debe permitir trazabilidad end-to-end de una solicitud desde el Frontend hasta la BD, cumpliendo con generar y propagar un Correlation ID en 100% de las solicitudes. y) Registrar trazas y logs con ese ID en todos los componentes críticos. Permitir localizar el recorrido completo de una solicitud en ≤ 2 minutos para incidentes reportados. z) Retener: logs por ≥ 30 días, traces por ≥ 7–14 días con muestreo configurable. | Para asegurar el monitoreo constante, Amazon CloudWatch y AWS X-Ray permiten rastrear cada solicitud de reserva mediante un Correlation ID, lo que facilita la visualización del mapa completo de la operación en menos de 2 minutos; este sistema de observabilidad se rige por la regla técnica de alertas en menos de 60 segundos, garantizando una notificación inmediata al equipo técnico si se detectan anomalías severas o cuellos de botella en el servicio. |
| **14** | **Desplegabilidad** | Los despliegues deben ser seguros y reversibles, cumpliendo: Estrategia de despliegue: Rolling update para cambios menores, Blue/Green para cambios de riesgo (migraciones, cambios de API, etc.). Downtime máximo 60 segundos por despliegue (objetivo: cero downtime, pero acotas). Rollback automático < 5 minutos si: tasa de errores 5xx supera 1% por 3 minutos, o latencia p95 del endpoint crítico sube más de 50% respecto a baseline por 5 minutos. | Finalmente, la gestión y actualización del ecosistema se realiza mediante AWS CodePipeline y CodeDeploy, que permiten actualizar la biblioteca utilizando una "Sede Espejo" (Blue/Green) para evitar cualquier corte de servicio durante los despliegues; este proceso incluye una regla técnica de Rollback en menos de 5 minutos, lo que garantiza un regreso automático a la versión estable anterior si se detectan errores de latencia o fallos críticos. Para dar soporte a toda esta infraestructura, se utilizan Terraform y Ansible, herramientas que automatizan la creación de la VPC, instancias EC2 y bases de datos, asegurando que el entorno sea reproducible y consistente; la integridad de estas operaciones se mantiene gracias a la regla de State Locking, la cual utiliza S3 para evitar conflictos de despliegue cuando varios ingenieros trabajan sobre la misma infraestructura simultáneamente. |

![Diagrama](/ruta/a/tu/imagen/delete.png)

## **4. FLUJO DE LA ARQUITECTURA EN AWS**:

| N° | Atributo de Calidad | Tecnología AWS | ¿Cómo se comunican? (Flujo de Comunicación) | ¿Qué pasa en cada servicio? (Flujo Crítico) |
|:--:|:---|:---|:---|:---|
| **1** | **Rendimiento** (Que sea rápido) | Route53 + Global Accelerator | El alumno escribe www.seabook.com → Route53 elige el servidor más cercano → Global Accelerator crea un "camino rápido" → Llega al balanceador (ALB) | 15 sedes conectadas → Buscan en un catálogo de 50GB → Respuesta en menos de 200ms (como un parpadeo) |
| **2** | **Seguridad** (Que sea seguro) | Shield + WAF + Cognito + API Gateway + Secrets Manager + IAM + VPC | El alumno intenta entrar → WAF solo permite 10 intentos por minuto → API Gateway revisa su credencial → Cognito verifica que sea alumno real → Entra a la red privada (VPC) | Inicio de sesión → Cognito pide doble verificación (MFA) → Genera un pase digital (JWT) → API Gateway revisa el pase → IAM asigna permisos específicos |
| **3** | **Resiliencia** (Que no se caiga) | ALB + Health Checks | El balanceador (ALB) revisa los servidores → Pregunta cada 5 segundos si están vivos → Si uno falla, manda el tráfico a otro en menos de 5 segundos | ALB revisa cada 5 segundos la ruta "/health" → Si un servidor no responde bien → Desvía alumnos automáticamente |
| **4** | **Disponibilidad + Escalabilidad** (Que siempre funcione y crezca) | EKS + HPA/VPA | El orquestador (EKS) administra los servidores → HPA monitorea el uso de CPU → Si llega al 80%, crea más servidores automáticamente | Semana de exámenes: 1000 reservas por segundo → HPA crea automáticamente 10 servidores para atender la demanda |
| **5** | **Mantenibilidad** (Que sea fácil de mantener) | App Mesh + Service Discovery | El servicio de Reservas necesita hablar con el de Usuarios → App Mesh los conecta de forma segura → Cloud Map permite encontrarse aunque cambien de lugar | Solicitud POST para validar reserva → Reservas consulta a Usuarios → Si falla, reintenta 2 veces |
| **6** | **Rendimiento** (Búsquedas rápidas) | ElastiCache (Redis) + OpenSearch | Cuando buscas un libro → Revisa primero la "memoria rápida" (Redis) → Si no está, busca en el catálogo completo (OpenSearch) | Búsqueda GET → Si está en Redis: respuesta en 2ms → Si no, busca en OpenSearch: respuesta en 200ms |
| **7** | **Fiabilidad** (Datos confiables) | Aurora Serverless v2 + Multi-AZ | Los servicios guardan información → Aurora la almacena → Multi-AZ crea copias en diferentes zonas → Todo bajo reglas ACID (sin pérdidas) | Reserva POST → Servicio de Reservas → Aurora guarda escritura con ACID → Todo en menos de 50ms |
| **8** | **Resiliencia + Rendimiento** (Procesos en segundo plano) | SQS FIFO + DLQ + Lambda + SNS | Al hacer una reserva → El pedido va a una cola (SQS) → Lambda genera el comprobante PDF (30 seg) → SNS envía notificación por correo | Reserva POST → Entra a cola FIFO (orden estricto) → Lambda genera PDF en segundo plano → SNS notifica al alumno |
| **9** | **Recuperabilidad** (Ante desastres) | AWS Backup + Multi-AZ | Un plan de respaldo programa copias → Guarda Aurora/Redis/OpenSearch en una bóveda segura → Si todo falla, recuperación en menos de 15 min | Si una zona cae (ej. Lima) → Activar zona secundaria (Trujillo) → Pérdida máxima de datos: 5 minutos |
| **10** | **Auditabilidad** (Registro de todo) | CloudTrail + S3 Object Lock | Cada acción queda grabada → CloudTrail envía los registros a S3 → Object Lock los vuelve inmodificables por 365 días | Si alguien elimina un usuario → CloudTrail registra la acción → S3 guarda el registro sin posibilidad de borrado por 365 días |
| **11** | **Observabilidad** (Monitoreo) | CloudWatch + X-Ray | Cada solicitud recibe un ID único → CloudWatch guarda los logs → X-Ray sigue el rastro por todo el sistema → Alertas si CPU supera 80% por 5 min | Llega una solicitud → Se le asigna Correlation ID → X-Ray traza su camino → CloudWatch alerta si algo falla en menos de 60 segundos |
| **12** | **Desplegabilidad** (Actualizaciones sin caídas) | CodePipeline + CodeDeploy + ECR + Terraform | El programador hace git push → CodePipeline inicia el proceso → CodeDeploy actualiza con Blue/Green (servidores espejo) → Si hay error, vuelve atrás en 5 min | git push al repositorio → Escaneo de seguridad en ECR → Despliegue Blue/Green (sin caídas) → Si hay errores, rollback automático en 5 min |

##  **5. CUADRO DE PASOS SEGUIDOS EN EL PROCESO DEl DESARROLLO DEL CODIGO**:

| Requisito / Atributo de Calidad | Tecnología AWS | Justificación Técnica | Documentación | Documentación |
| :--- | :--- | :--- | :--- | :--- |
| Rendimiento | Amazon Route 53 | Gestión de DNS y enrutamiento de tráfico. | [aws_route53_record \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record) | |
| Rendimiento | AWS Global Accelerator | Mejora de latencia global. | [aws_globalaccelerator_accelerat...](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/globalaccelerator_accelerator) | |
| Seguridad | AWS Shield | Protección contra ataques DDoS. | [aws_shield_protection \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/shield_protection) | |
| Seguridad | AWS WAF | Firewall para aplicaciones web. | [aws_wafv2_web_acl \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/wafv2_web_acl) | |
| Seguridad | Amazon Cognito | Autenticación y gestión de usuarios. | [aws_cognito_user_pool \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cognito_user_pool) | |
| Seguridad | Amazon API Gateway | Gestión y seguridad de endpoints API. | [aws_apigatewayv2_api \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/apigatewayv2_api) | [aws_api_gateway_rest_api \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_rest_api) |
| Resiliencia | Application Load Balancer (ALB) | Balanceo de carga y Health Checks. | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb> | |
| Escalabilidad | Amazon EC2 Auto Scaling | Escalado horizontal automático. | [aws_autoscaling_group \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group) | [Manage AWS Auto Scaling Groups \| Terraform \| HashiCorp Developer](https://developer.hashicorp.com/terraform/tutorials/aws/aws-asg) |
| Disponibilidad | Amazon EKS (Kubernetes) | Orquestación de contenedores. | [aws_eks_cluster \| Resources \| hashicorp/aws \| Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster) | [Provision an EKS cluster (AWS) \| Terraform \| HashiCorp Developer](https://developer.hashicorp.com/terraform/tutorials/kubernetes/eks) |
| Mantenibilidad | Amazon App Mesh | Estandariza la comunicación entre microservicios sin cambiar el código | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/appmesh_mesh> | |
| Rendimiento | Amazon ElastiCache (Redis) y y OpenSearch índices GIN | Cache de baja latencia y búsquedas indexadas ultra rápidas (índices GIN) | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elasticache_cluster> / <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/opensearch_domain> | |
| Fiabilidad | Amazon Aurora Serverless v2 Multi-AZ | Base de datos relacional con escalado automático y alta disponibilidad | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster> | |
| Resiliencia | Amazon SQS (FIFO) | Garantiza la entrega de mensajes y el orden exacto para evitar duplicidad | <https://registry.terraform.io/providers/-/aws/latest/docs/resources/sqs_queue> | |
| Recuperabilidad | SQS Dead Letter Queue (DLQ) | Aislamiento de mensajes fallidos para análisis y reintento posterior | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue_redrive_policy> | |
| Rendimiento | Serverless utilizando AWS Lambda y Amazon SNS | Ejecución de lógica basada en eventos sin gestionar servidores | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function> / <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic> | |
| Auditabilidad | AWS CloudTrail y Amazon S3 Object Lock | Registro de actividad de API y almacenamiento inmutable de logs | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail> / <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_object_lock_configuration> | |
| Observabilidad | Amazon CloudWatch y AWS X-Ray | Monitoreo de métricas, logs y trazabilidad de peticiones de extremo a extremo | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm> / <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/xray_group> | |
| Despliegue | AWS CodePipeline y CodeDeploy , Terraform y Ansible | Automatización de CI/CD y gestión de Infraestructura como Código (IaC) | <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/codepipeline> / <https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/codedeploy_app> | |

##  **6. CUADRO DE PASOS SEGUIDOS EN EL PROCESO DE TESTING CON COMANDOS UTILIZADOS**:

| N° | Paso realizado | Descripción | Comandos utilizados | Buenas prácticas aplicadas | Autores que respaldan |
|:--:|:---|:---|:---|:---|:---|
| **1** | **Inicialización del proyecto** | Se configuró el proyecto Node.js para poder trabajar con testing automatizado. | `npm init -y` | Preparación de entorno controlado para pruebas. | **Kent Beck** – Destaca la importancia de preparar el entorno dentro del Desarrollo Guiado por Pruebas (TDD). |
| **2** | **Instalación de Jest** | Se instaló Jest como herramienta principal para ejecutar pruebas unitarias. | `npm install --save-dev jest` | Uso de herramientas estándar de la industria. | **Kent Beck** – Promueve el uso de herramientas que permitan automatizar pruebas. |
| **3** | **Configuración de Jest** | Se configuró el script de pruebas dentro del archivo package.json. | `"test": "jest"` (en package.json) | Automatización del proceso de testing. | **Kent Beck** – Relacionado con el ciclo Red-Green-Refactor. |
| **4** | **Creación del archivo de pruebas** | Se creó el archivo donde se definieron los tests. | `calculadora.test.js` | Organización del código y separación entre lógica y pruebas. | **Robert C. Martin** – Promueve la separación de responsabilidades en Clean Code. |
| **5** | **Desarrollo de pruebas pequeñas y enfocadas** | Se escribieron pruebas individuales para validar comportamientos específicos. | `test()` o `it()` | Pruebas pequeñas y enfocadas. | **Kent Beck** – Recomienda pruebas simples y específicas dentro del TDD. |
| **6** | **Uso de nombres descriptivos** | Se asignaron nombres claros que indican qué comportamiento se valida. | `test("suma de dos numeros enteros positivos")` | Uso de nombres descriptivos. | **Robert C. Martin** – Indica que los nombres deben expresar la intención del código. |
| **7** | **Uso del patrón AAA** | Se organizaron los tests en Arrange (Preparar), Act (Ejecutar) y Assert (Verificar). | Variables de prueba → ejecutar función → `expect(resultado).toBe()` | Estructura organizada de pruebas. | **Bill Wake** – Creador del patrón AAA utilizado en pruebas unitarias. |
| **8** | **Validación de resultados correctos** | Se verificó que la función retorne el resultado esperado. | `expect(resultado).toBe(valorEsperado)` | Pruebas basadas en comportamiento. | **Kent Beck** – Establece que las pruebas deben validar comportamientos observables del sistema. |
| **9** | **Validación de manejo de errores** | Se comprobó que la función lance excepciones ante datos inválidos. | `expect(() => suma()).toThrow()` | Pruebas de casos borde (Edge Cases). | **Glenford Myers, Martin Fowler, Jim Shore** – Destacan la importancia de probar límites y el principio Fail-Fast. |
| **10** | **Independencia de pruebas** | Cada prueba se ejecuta sin depender de otra, usando sus propios datos. | Cada test con sus propios datos de prueba | Independencia de pruebas. | **Kent Beck** – Señala que cada prueba debe ejecutarse de manera independiente en TDD. |
| **11** | **Ejecución automatizada de pruebas** | Se ejecutaron todos los tests para verificar el funcionamiento del sistema. | `npm test` | Automatización y validación continua. | **Kent Beck** – Propone ejecutar pruebas constantemente durante el desarrollo. |
| **12** | **Verificación de resultados** | Se revisaron los reportes generados por Jest para confirmar que todas las pruebas pasen correctamente. | Salida en consola de Jest (resultados de pruebas) | Desarrollo de software confiable y robusto. | **Glenford Myers** – Indica que el testing permite detectar fallos y mejorar la calidad del software. |

## **Comandos de ejecución**:
+ Antes de nada, activamos nuestra cuenta en aws y los IAM para en la terminal ejecutar el "aws configure sso"
+ Se selecciona un usuario, en nuestro caso usamos "Seabook"
+ Seguimos los pasos, y ya tenemos activado el aws

Para los archivos terraform, tenemos lo siguiente:
 + Inicialización:
```bash
terraform init
terraform update
```
  Gestión de entornos:

El proyecto utiliza la función terraform.workspace :para los recursos, así que se va a crear el usuario a trabajar
```bash
terraform workspace new dev (ejemplo)
```
Si ya existe más de uno entonces se escoje cual
```bash
terraform workspace select dev
```
Planificación: Se visualiza la sintaxis del código para asegurar que no hayan errores de esta misma
```bash
terraform plan
```
Despliegue: Para la creación de los servicios
```bash
terraform apply
```
+ Limpieza opcional: Al acabar, se pueden borrar todo lo creado
```bash
terraform destroy
```
## Consideraciones:
## Resultados


- Anton Figueroa, Raul
- Chavez Segura, Cristhoper
- Rivera Chamorro, Kristel 
- Saldaña Ylquimiche, Oliver
- Velasquez Avalos, Marycielo
